{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# Real-Time Anomaly Detection - Complete Analysis"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\nsys.path.append('../src')\nfrom detectors.pipeline import *\nfrom visualizations import AnomalyVisualizer\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Generate Synthetic Data"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Generating synthetic time series...')\ndata, true_labels = generate_synthetic_data(n_points=1000, anomaly_rate=0.05)\n\nprint(f'Created {len(data)} points with {np.sum(true_labels)} true anomalies')\n\nplt.figure(figsize=(14, 4))\nplt.plot(data, linewidth=1, alpha=0.7)\nplt.title('Synthetic Time Series')\nplt.xlabel('Time')\nplt.ylabel('Value')\nplt.grid(alpha=0.3)\nplt.show()"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Train Detector"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_size = 500\ntrain_data = data[:train_size]\ntest_data = data[train_size:]\ntest_labels = true_labels[train_size:]\n\npipeline = StreamingPipeline(detector_type='ensemble')\npipeline.train(train_data)\n\nprint(f'Training: {len(train_data)} points')\nprint(f'Testing: {len(test_data)} points')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Detect Anomalies"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = pipeline.process_stream(test_data)\n\nprint(f'\\nDetected {len(pipeline.anomalies)} anomalies')\nprint(f'True anomalies in test: {np.sum(test_labels)}')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Visualize Results"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["viz = AnomalyVisualizer('../assets')\n\n# Time series with anomalies\nviz.plot_time_series_with_anomalies(test_data, pipeline.anomalies, save=False)\n\n# Anomaly scores\nscores = [r['score'] for r in results['results']]\nviz.plot_anomaly_scores(np.array(scores), save=False)"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Evaluate Performance"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["predictions = np.array([r['is_anomaly'] for r in results['results']])\nmetrics = evaluate_detector(predictions, test_labels)\n\nprint('Performance Metrics:')\nfor metric, value in metrics.items():\n    if isinstance(value, float):\n        print(f'  {metric}: {value:.3f}')\n    else:\n        print(f'  {metric}: {value}')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Complete Dashboard"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["viz.create_dashboard(test_data, pipeline.anomalies, np.array(scores), metrics, save=False)"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Conclusion\n\nThis demonstrates:\n- Multiple detection algorithms\n- Ensemble voting\n- Real-time processing\n- Performance evaluation\n- Comprehensive visualizations"]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}},
 "nbformat": 4,
 "nbformat_minor": 4
}
